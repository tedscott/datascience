---
title: "Getting & Cleaning Quiz 2"
author: "tedscott"
date: "December 20, 2015"
output: html_document
---

Work to answer the questions in Getting & Cleaning data quiz 2


Question 1

```{r}
#question 1 using the github api

# follow tutorial at 
# https://github.com/hadley/httr/blob/master/demo/oauth2-github.r
library(httpuv)

# Find OAuth settings for github:
# http://developer.github.com/v3/oauth/
oauth_endpoints("github")

# made an app at https://github.com/settings/applications/278277
GitHubApp <- oauth_app("github", key="4e84f1419585f28d78fc", secret="c6f333279e9396da3a055a51edec694c3847a76c")

# Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), GitHubApp)

# Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
jsonContent <- content(req)
json2 <- jsonlite::fromJSON(toJSON(jsonContent))

# what are the field names?
names(json2)

# get the created date for the datasharing repo
json2$created_at[json2$name=="datasharing"]
```

Question 2 & 3

```{r}
# read in american community survey csv
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileURL, destfile="./acs.csv")
acs <- read.csv("./acs.csv")

# detach RMySQL to avoid conflicts
detach("package:RMySQL", unload=TRUE)

# now use the sqldf package
library(sqldf)

# question 2
result <- sqldf("select pwgtp1 from acs where AGEP < 50")

# question 3
unique(acs$AGEP)
result2 <- sqldf("select distinct AGEP from acs")
result2

```

Question 4

```{r}
# How many characters are in the 10th, 20th, 30th and 100th lines of HTML from this page: 
# http://biostat.jhsph.edu/~jleek/contact.html 
# (Hint: the nchar() function in R may be helpful)

# extract contents of website
# using html parsing functions
fileURL <- "http://biostat.jhsph.edu/~jleek/contact.html"
#doc <- htmlTreeParse(fileURL, useInternal=TRUE)
#rootNode <- xmlRoot(doc)
library(httr)
htmlq4 = GET(fileURL)
contentq4 = content(htmlq4, as="text")
parsedq4 = htmlParse(contentq4, asText = TRUE)

# now access specific lines
capture.output(parsedq4)

# the rows we care about
rows <- c(10,20,30,100)

# two ways to get the num chars
lapply(capture.output(parsedq4)[rows],nchar)
nchar(capture.output(parsedq4)[rows])

# the above gives the wrong result, so instead try
con=url(fileURL)
htmlcode <- readLines(con)
htmlcode[1:9] # looks to be working since it matches
#https://thoughtfulbloke.wordpress.com/2015/09/09/getting-and-cleaning-week-2/

# which gives the right answer
nchar(htmlcode[rows])


```

Question 5
Read this data set into R and report the sum of the numbers in the fourth of the nine columns. 


```{r}
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"

download.file(fileURL, destfile="./data.for")
theFile <- read.fwf("./data.for", skip=4,widths=c(12, 7, 4, 9, 4, 9, 4, 9, 4))
# widths obtained from http://stackoverflow.com/questions/14383710/read-fixed-width-text-file
sum(theFile[,4])

```


